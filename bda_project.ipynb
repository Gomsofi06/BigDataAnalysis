{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import re\n",
    "\n",
    "def load_and_label_eeg(patient, file_numbers, pre_seizure_duration=100):\n",
    "    \"\"\"\n",
    "    Carrega e processa arquivos EEG EDF para um paciente específico.\n",
    "\n",
    "    Args:\n",
    "        patient (str): Número do paciente (ex: \"08\").\n",
    "        file_numbers (list): Lista de números dos arquivos a carregar (ex: [\"02\", \"05\"]).\n",
    "        pre_seizure_duration (int): Tempo antes da crise para marcar como 1 (ajustável).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com os dados EEG e labels aplicados.\n",
    "    \"\"\"\n",
    "\n",
    "    # Lista para armazenar DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Carregar arquivos EDF\n",
    "    for file_num in file_numbers:\n",
    "        file_name = f\"chb{patient}_{file_num}\"  # Nome do arquivo sem extensão\n",
    "        file_path = f\"data/{file_name}.edf\"  # Caminho completo\n",
    "\n",
    "        if os.path.exists(file_path):  \n",
    "            print(f\"Loading {file_path}...\")\n",
    "            \n",
    "            raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "            data, times = raw[:]\n",
    "            \n",
    "            df_temp = pd.DataFrame(data.T, columns=raw.ch_names)\n",
    "            df_temp[\"time\"] = times  \n",
    "            df_temp[\"file\"] = file_name  # Adiciona sem a extensão .edf\n",
    "            \n",
    "            dfs.append(df_temp)\n",
    "        else:\n",
    "            print(f\"File {file_path} not found. Skipping...\")\n",
    "\n",
    "    # Criar DataFrame final\n",
    "    if not dfs:\n",
    "        print(\"Nenhum arquivo carregado. Retornando DataFrame vazio.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Inicializar coluna de labels\n",
    "    df[\"label\"] = 0  \n",
    "\n",
    "    # Ler resumo\n",
    "    summary_file = f\"data/chb{patient}-summary.txt\"\n",
    "\n",
    "    if not os.path.exists(summary_file):\n",
    "        print(f\"Summary file {summary_file} not found. Returning DataFrame without labels.\")\n",
    "        return df\n",
    "\n",
    "    with open(summary_file, \"r\") as f:\n",
    "        summary_text = f.read()\n",
    "\n",
    "    # Encontrar arquivos e crises no resumo\n",
    "    file_seizures = {}\n",
    "    seizure_pattern = re.compile(rf\"File Name: (chb{patient}_\\d+)\\.edf.*?Number of Seizures in File: (\\d+)(.*?)\\n\\n\", re.DOTALL)\n",
    "\n",
    "    for file, num_seizures, details in seizure_pattern.findall(summary_text):\n",
    "        num_seizures = int(num_seizures)\n",
    "        \n",
    "        if num_seizures > 0:  \n",
    "            seizure_times = re.findall(r\"Seizure \\d+ Start Time: (\\d+) seconds\\nSeizure \\d+ End Time: (\\d+) seconds\", details)\n",
    "            file_seizures[file] = [(int(start), int(end)) for start, end in seizure_times]\n",
    "\n",
    "    # Aplicar labels se houver crises\n",
    "    for file, seizures in file_seizures.items():\n",
    "        for start, end in seizures:\n",
    "            df.loc[(df[\"file\"] == file) & (df[\"time\"] >= start - pre_seizure_duration) & (df[\"time\"] < start), \"label\"] = 1\n",
    "            df.loc[(df[\"file\"] == file) & (df[\"time\"] >= start) & (df[\"time\"] <= end), \"label\"] = 2\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/chb08_02.edf...\n",
      "Extracting EDF parameters from c:\\Users\\ASUS.LAPTOP-SFDPA4G4\\Desktop\\Faculdade\\Mestrado\\2semestre\\BDA\\BDA_project\\data\\chb08_02.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS.LAPTOP-SFDPA4G4\\AppData\\Local\\Temp\\ipykernel_12536\\3670794891.py:31: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/chb08_05.edf...\n",
      "Extracting EDF parameters from c:\\Users\\ASUS.LAPTOP-SFDPA4G4\\Desktop\\Faculdade\\Mestrado\\2semestre\\BDA\\BDA_project\\data\\chb08_05.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS.LAPTOP-SFDPA4G4\\AppData\\Local\\Temp\\ipykernel_12536\\3670794891.py:31: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/chb08_11.edf...\n",
      "Extracting EDF parameters from c:\\Users\\ASUS.LAPTOP-SFDPA4G4\\Desktop\\Faculdade\\Mestrado\\2semestre\\BDA\\BDA_project\\data\\chb08_11.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS.LAPTOP-SFDPA4G4\\AppData\\Local\\Temp\\ipykernel_12536\\3670794891.py:31: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/chb08_13.edf...\n",
      "Extracting EDF parameters from c:\\Users\\ASUS.LAPTOP-SFDPA4G4\\Desktop\\Faculdade\\Mestrado\\2semestre\\BDA\\BDA_project\\data\\chb08_13.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS.LAPTOP-SFDPA4G4\\AppData\\Local\\Temp\\ipykernel_12536\\3670794891.py:31: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/chb08_21.edf...\n",
      "Extracting EDF parameters from c:\\Users\\ASUS.LAPTOP-SFDPA4G4\\Desktop\\Faculdade\\Mestrado\\2semestre\\BDA\\BDA_project\\data\\chb08_21.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS.LAPTOP-SFDPA4G4\\AppData\\Local\\Temp\\ipykernel_12536\\3670794891.py:31: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(file_path, preload=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP1-F7</th>\n",
       "      <th>F7-T7</th>\n",
       "      <th>T7-P7</th>\n",
       "      <th>P7-O1</th>\n",
       "      <th>FP1-F3</th>\n",
       "      <th>F3-C3</th>\n",
       "      <th>C3-P3</th>\n",
       "      <th>P3-O1</th>\n",
       "      <th>FP2-F4</th>\n",
       "      <th>F4-C4</th>\n",
       "      <th>...</th>\n",
       "      <th>FZ-CZ</th>\n",
       "      <th>CZ-PZ</th>\n",
       "      <th>P7-T7</th>\n",
       "      <th>T7-FT9</th>\n",
       "      <th>FT9-FT10</th>\n",
       "      <th>FT10-T8</th>\n",
       "      <th>T8-P8-1</th>\n",
       "      <th>time</th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.611722e-04</td>\n",
       "      <td>2.637363e-05</td>\n",
       "      <td>-1.953602e-07</td>\n",
       "      <td>7.873016e-05</td>\n",
       "      <td>-4.161172e-05</td>\n",
       "      <td>7.833944e-05</td>\n",
       "      <td>-3.936508e-04</td>\n",
       "      <td>3.006593e-04</td>\n",
       "      <td>1.799267e-04</td>\n",
       "      <td>8.029304e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.113553e-05</td>\n",
       "      <td>7.755800e-05</td>\n",
       "      <td>5.860806e-07</td>\n",
       "      <td>5.411477e-05</td>\n",
       "      <td>2.676435e-05</td>\n",
       "      <td>5.528694e-05</td>\n",
       "      <td>5.958486e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>chb08_02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>chb08_02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>-1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>9.768010e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>5.860806e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>1.758242e-06</td>\n",
       "      <td>-9.768010e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>chb08_02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.768010e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>-1.367521e-06</td>\n",
       "      <td>3.321123e-06</td>\n",
       "      <td>-9.768010e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>-1.953602e-07</td>\n",
       "      <td>2.148962e-06</td>\n",
       "      <td>-9.768010e-07</td>\n",
       "      <td>-1.758242e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>-5.860806e-07</td>\n",
       "      <td>1.758242e-06</td>\n",
       "      <td>-2.539683e-06</td>\n",
       "      <td>2.930403e-06</td>\n",
       "      <td>-1.953602e-07</td>\n",
       "      <td>5.860806e-07</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>chb08_02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.102564e-06</td>\n",
       "      <td>5.274725e-06</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>-2.930403e-06</td>\n",
       "      <td>-9.768010e-07</td>\n",
       "      <td>2.148962e-06</td>\n",
       "      <td>-1.953602e-07</td>\n",
       "      <td>-2.539683e-06</td>\n",
       "      <td>5.860806e-07</td>\n",
       "      <td>-2.930403e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>9.768010e-07</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>-2.539683e-06</td>\n",
       "      <td>-1.269841e-05</td>\n",
       "      <td>1.660562e-05</td>\n",
       "      <td>-1.953602e-07</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>chb08_02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607995</th>\n",
       "      <td>-1.699634e-05</td>\n",
       "      <td>2.520147e-05</td>\n",
       "      <td>-6.466422e-05</td>\n",
       "      <td>1.230769e-05</td>\n",
       "      <td>-8.302808e-05</td>\n",
       "      <td>5.802198e-05</td>\n",
       "      <td>2.539683e-06</td>\n",
       "      <td>-2.324786e-05</td>\n",
       "      <td>-1.347985e-05</td>\n",
       "      <td>4.903541e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.324786e-05</td>\n",
       "      <td>-6.837607e-06</td>\n",
       "      <td>6.505495e-05</td>\n",
       "      <td>-5.372405e-05</td>\n",
       "      <td>3.770452e-05</td>\n",
       "      <td>6.935287e-05</td>\n",
       "      <td>-6.114774e-05</td>\n",
       "      <td>3599.980469</td>\n",
       "      <td>chb08_21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607996</th>\n",
       "      <td>-1.738706e-05</td>\n",
       "      <td>-2.871795e-05</td>\n",
       "      <td>-3.418803e-05</td>\n",
       "      <td>3.223443e-05</td>\n",
       "      <td>-8.302808e-05</td>\n",
       "      <td>5.997558e-05</td>\n",
       "      <td>5.274725e-06</td>\n",
       "      <td>-3.223443e-05</td>\n",
       "      <td>-1.894994e-05</td>\n",
       "      <td>5.411477e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.598291e-05</td>\n",
       "      <td>-9.963370e-06</td>\n",
       "      <td>3.457875e-05</td>\n",
       "      <td>1.758242e-06</td>\n",
       "      <td>3.770452e-05</td>\n",
       "      <td>2.520147e-05</td>\n",
       "      <td>-2.168498e-05</td>\n",
       "      <td>3599.984375</td>\n",
       "      <td>chb08_21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607997</th>\n",
       "      <td>-5.860806e-07</td>\n",
       "      <td>-9.787546e-05</td>\n",
       "      <td>6.837607e-06</td>\n",
       "      <td>5.684982e-05</td>\n",
       "      <td>-6.388278e-05</td>\n",
       "      <td>5.724054e-05</td>\n",
       "      <td>-4.102564e-06</td>\n",
       "      <td>-2.442002e-05</td>\n",
       "      <td>-3.457875e-05</td>\n",
       "      <td>5.059829e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.934066e-05</td>\n",
       "      <td>-9.963370e-06</td>\n",
       "      <td>-6.446886e-06</td>\n",
       "      <td>6.935287e-05</td>\n",
       "      <td>3.184371e-05</td>\n",
       "      <td>-5.274725e-06</td>\n",
       "      <td>-2.148962e-06</td>\n",
       "      <td>3599.988281</td>\n",
       "      <td>chb08_21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607998</th>\n",
       "      <td>5.528694e-05</td>\n",
       "      <td>-7.013431e-05</td>\n",
       "      <td>9.045177e-05</td>\n",
       "      <td>-5.450549e-05</td>\n",
       "      <td>4.200244e-05</td>\n",
       "      <td>8.009768e-06</td>\n",
       "      <td>-7.619048e-06</td>\n",
       "      <td>-2.207570e-05</td>\n",
       "      <td>-4.473748e-05</td>\n",
       "      <td>5.137973e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.816850e-05</td>\n",
       "      <td>-7.228327e-06</td>\n",
       "      <td>-9.006105e-05</td>\n",
       "      <td>4.903541e-05</td>\n",
       "      <td>2.559219e-05</td>\n",
       "      <td>-2.285714e-05</td>\n",
       "      <td>1.269841e-05</td>\n",
       "      <td>3599.992188</td>\n",
       "      <td>chb08_21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607999</th>\n",
       "      <td>7.247863e-05</td>\n",
       "      <td>-3.809524e-05</td>\n",
       "      <td>9.435897e-05</td>\n",
       "      <td>-9.006105e-05</td>\n",
       "      <td>7.013431e-05</td>\n",
       "      <td>1.953602e-07</td>\n",
       "      <td>-3.711844e-06</td>\n",
       "      <td>-2.793651e-05</td>\n",
       "      <td>-3.965812e-05</td>\n",
       "      <td>5.724054e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.129426e-05</td>\n",
       "      <td>-6.056166e-06</td>\n",
       "      <td>-9.396825e-05</td>\n",
       "      <td>2.598291e-05</td>\n",
       "      <td>2.207570e-05</td>\n",
       "      <td>-2.949939e-05</td>\n",
       "      <td>2.520147e-05</td>\n",
       "      <td>3599.996094</td>\n",
       "      <td>chb08_21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608000 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               FP1-F7         F7-T7         T7-P7         P7-O1        FP1-F3  \\\n",
       "0       -1.611722e-04  2.637363e-05 -1.953602e-07  7.873016e-05 -4.161172e-05   \n",
       "1        1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07   \n",
       "2        1.953602e-07 -1.953602e-07  1.953602e-07  9.768010e-07  1.953602e-07   \n",
       "3       -9.768010e-07  1.953602e-07 -1.367521e-06  3.321123e-06 -9.768010e-07   \n",
       "4       -4.102564e-06  5.274725e-06  1.953602e-07 -2.930403e-06 -9.768010e-07   \n",
       "...               ...           ...           ...           ...           ...   \n",
       "4607995 -1.699634e-05  2.520147e-05 -6.466422e-05  1.230769e-05 -8.302808e-05   \n",
       "4607996 -1.738706e-05 -2.871795e-05 -3.418803e-05  3.223443e-05 -8.302808e-05   \n",
       "4607997 -5.860806e-07 -9.787546e-05  6.837607e-06  5.684982e-05 -6.388278e-05   \n",
       "4607998  5.528694e-05 -7.013431e-05  9.045177e-05 -5.450549e-05  4.200244e-05   \n",
       "4607999  7.247863e-05 -3.809524e-05  9.435897e-05 -9.006105e-05  7.013431e-05   \n",
       "\n",
       "                F3-C3         C3-P3         P3-O1        FP2-F4         F4-C4  \\\n",
       "0        7.833944e-05 -3.936508e-04  3.006593e-04  1.799267e-04  8.029304e-05   \n",
       "1        1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07   \n",
       "2        1.953602e-07  1.953602e-07  5.860806e-07  1.953602e-07  1.953602e-07   \n",
       "3        1.953602e-07 -1.953602e-07  2.148962e-06 -9.768010e-07 -1.758242e-06   \n",
       "4        2.148962e-06 -1.953602e-07 -2.539683e-06  5.860806e-07 -2.930403e-06   \n",
       "...               ...           ...           ...           ...           ...   \n",
       "4607995  5.802198e-05  2.539683e-06 -2.324786e-05 -1.347985e-05  4.903541e-05   \n",
       "4607996  5.997558e-05  5.274725e-06 -3.223443e-05 -1.894994e-05  5.411477e-05   \n",
       "4607997  5.724054e-05 -4.102564e-06 -2.442002e-05 -3.457875e-05  5.059829e-05   \n",
       "4607998  8.009768e-06 -7.619048e-06 -2.207570e-05 -4.473748e-05  5.137973e-05   \n",
       "4607999  1.953602e-07 -3.711844e-06 -2.793651e-05 -3.965812e-05  5.724054e-05   \n",
       "\n",
       "         ...         FZ-CZ         CZ-PZ         P7-T7        T7-FT9  \\\n",
       "0        ...  1.113553e-05  7.755800e-05  5.860806e-07  5.411477e-05   \n",
       "1        ...  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07   \n",
       "2        ...  1.953602e-07  1.953602e-07  1.953602e-07  1.953602e-07   \n",
       "3        ...  1.953602e-07 -5.860806e-07  1.758242e-06 -2.539683e-06   \n",
       "4        ...  1.953602e-07  9.768010e-07  1.953602e-07 -2.539683e-06   \n",
       "...      ...           ...           ...           ...           ...   \n",
       "4607995  ...  2.324786e-05 -6.837607e-06  6.505495e-05 -5.372405e-05   \n",
       "4607996  ...  2.598291e-05 -9.963370e-06  3.457875e-05  1.758242e-06   \n",
       "4607997  ...  1.934066e-05 -9.963370e-06 -6.446886e-06  6.935287e-05   \n",
       "4607998  ...  1.816850e-05 -7.228327e-06 -9.006105e-05  4.903541e-05   \n",
       "4607999  ...  2.129426e-05 -6.056166e-06 -9.396825e-05  2.598291e-05   \n",
       "\n",
       "             FT9-FT10       FT10-T8       T8-P8-1         time      file  \\\n",
       "0        2.676435e-05  5.528694e-05  5.958486e-05     0.000000  chb08_02   \n",
       "1        1.953602e-07  1.953602e-07  1.953602e-07     0.003906  chb08_02   \n",
       "2        1.758242e-06 -9.768010e-07  1.953602e-07     0.007812  chb08_02   \n",
       "3        2.930403e-06 -1.953602e-07  5.860806e-07     0.011719  chb08_02   \n",
       "4       -1.269841e-05  1.660562e-05 -1.953602e-07     0.015625  chb08_02   \n",
       "...               ...           ...           ...          ...       ...   \n",
       "4607995  3.770452e-05  6.935287e-05 -6.114774e-05  3599.980469  chb08_21   \n",
       "4607996  3.770452e-05  2.520147e-05 -2.168498e-05  3599.984375  chb08_21   \n",
       "4607997  3.184371e-05 -5.274725e-06 -2.148962e-06  3599.988281  chb08_21   \n",
       "4607998  2.559219e-05 -2.285714e-05  1.269841e-05  3599.992188  chb08_21   \n",
       "4607999  2.207570e-05 -2.949939e-05  2.520147e-05  3599.996094  chb08_21   \n",
       "\n",
       "         label  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "4607995      0  \n",
       "4607996      0  \n",
       "4607997      0  \n",
       "4607998      0  \n",
       "4607999      0  \n",
       "\n",
       "[4608000 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parâmetros desejados\n",
    "patient = \"08\"\n",
    "file_numbers = [\"02\", \"05\", \"11\", \"13\", \"21\"]\n",
    "pre_seizure_duration = 100  # Ajustável\n",
    "\n",
    "# Chamar a função\n",
    "df = load_and_label_eeg(patient, file_numbers, pre_seizure_duration)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def scale_and_select_features(X_train, X_val, X_test, y_train, y_val):\n",
    "    \"\"\"\n",
    "    Scale the features and perform feature selection (RFE) once for all models.\n",
    "    \n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Training features.\n",
    "        X_val (pd.DataFrame): Validation features.\n",
    "        X_test (pd.DataFrame): Test features.\n",
    "        y_train (pd.Series): Training labels.\n",
    "        y_val (pd.Series): Validation labels.\n",
    "    \n",
    "    Returns:\n",
    "        X_train_rfe, X_val_rfe, X_test_rfe: Feature-selected and scaled data.\n",
    "    \"\"\"\n",
    "    # Step 1: Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Step 2: Feature Selection using RFE with Logistic Regression\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    rfe = RFE(estimator=model, n_features_to_select=5, verbose=2)  # Selecting top 5 features\n",
    "    X_train_rfe = rfe.fit_transform(X_train_scaled, y_train)\n",
    "    X_val_rfe = rfe.transform(X_val_scaled)\n",
    "    X_test_rfe = rfe.transform(X_test_scaled)\n",
    "    \n",
    "    return X_train_rfe, X_val_rfe, X_test_rfe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[\"label\", \"time\", \"file\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(X, y, test_size=0.15, val_size=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the data into training, validation, and test sets.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): Features (input data).\n",
    "        y (pd.Series): Labels (output data).\n",
    "        test_size (float): Proportion of the data to be used for the test set.\n",
    "        val_size (float): Proportion of the data to be used for the validation set.\n",
    "        random_state (int): Seed for reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "        X_train, X_val, X_test, y_train, y_val: Split data.\n",
    "    \"\"\"\n",
    "    # First, split the data into training set (70%) and temporary set (30%)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=(test_size + val_size), random_state=random_state, stratify=y)\n",
    "    \n",
    "    # Now split the temporary set into validation (50% of the temp set) and test (50% of the temp set)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=(test_size / (test_size + val_size)), random_state=random_state, stratify=y_temp)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "# Assuming you have your features X and labels y defined\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y)\n",
    "\n",
    "# Now you can use these sets for training, validation, and testing\n",
    "\n",
    "\n",
    "# Step 1: Scale the features and perform feature selection (RFE)\n",
    "X_train_rfe, X_val_rfe, X_test_rfe = scale_and_select_features(X_train, X_val, X_test, y_train, y_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "def train_logistic_model_with_grid_search(X_train_rfe, y_train, X_val_rfe, y_val):\n",
    "    \"\"\"\n",
    "    Train Logistic Regression model with GridSearchCV and calculate performance metrics.\n",
    "    \n",
    "    Args:\n",
    "        X_train_rfe (pd.DataFrame): Training data with selected features.\n",
    "        y_train (pd.Series): Labels for training data.\n",
    "        X_val_rfe (pd.DataFrame): Validation data with selected features.\n",
    "        y_val (pd.Series): Labels for validation data.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Results with best parameters, accuracy, and confusion matrix for Logistic Regression.\n",
    "    \"\"\"\n",
    "    # Define model and parameter grid\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1],\n",
    "    \"penalty\": ['l2', 'elasticnet', 'l1'],  # Regularization strength with a range of values\n",
    "    \"solver\": [\"lbfgs\"],  # Using lbfgs for faster convergence\n",
    "    \"class_weight\": [\"balanced\"],  # Adjust for class imbalance\n",
    "}\n",
    "\n",
    "    \n",
    "    # Step 1: Grid Search for Logistic Regression\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train_rfe, y_train)\n",
    "    \n",
    "    # Best model found\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_val_pred = best_model.predict(X_val_rfe)\n",
    "    \n",
    "    # Calculate validation accuracy\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    val_confusion = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\n🔹 Best Hyperparameters: {best_params}\")\n",
    "    print(f\"🔹 Validation Accuracy: {val_accuracy}\")\n",
    "    print(f\"🔹 Validation Confusion Matrix:\\n{val_confusion}\")\n",
    "\n",
    "    # Return results\n",
    "    return {\n",
    "        \"best_model\": best_model,\n",
    "        \"best_params\": best_params,\n",
    "        \"val_accuracy\": val_accuracy,\n",
    "        \"val_confusion_matrix\": val_confusion\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS.LAPTOP-SFDPA4G4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "18 fits failed out of a total of 27.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ASUS.LAPTOP-SFDPA4G4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\ASUS.LAPTOP-SFDPA4G4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ASUS.LAPTOP-SFDPA4G4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ASUS.LAPTOP-SFDPA4G4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ASUS.LAPTOP-SFDPA4G4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\ASUS.LAPTOP-SFDPA4G4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ASUS.LAPTOP-SFDPA4G4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ASUS.LAPTOP-SFDPA4G4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\ASUS.LAPTOP-SFDPA4G4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.28239552        nan        nan 0.28240482        nan        nan\n",
      " 0.28240575        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Best Hyperparameters: {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "🔹 Validation Accuracy: 0.31831886574074075\n",
      "🔹 Validation Confusion Matrix:\n",
      "[[200298 177054 259357]\n",
      " [  5984   5453   7763]\n",
      " [ 11394   9626  14271]]\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Train Logistic Regression model and get results\n",
    "results = train_logistic_model_with_grid_search(X_train_rfe, y_train, X_val_rfe, y_val)\n",
    "\n",
    "# The results will contain the best hyperparameters, accuracy, and confusion matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
